{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dj8a-jYvYiRQ"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "RfaibDwLYinQ",
    "outputId": "607eec52-1071-477a-c2ec-f7d6dc14021d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Shree.Charran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Shree.Charran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lOXMf4evTiBq"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "20SOlMYSTiB0",
    "outputId": "d125a5e4-bd64-48ca-c8b7-ad697df62694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 4 columns):\n",
      "Sentence #    47959 non-null object\n",
      "Word          1048575 non-null object\n",
      "POS           1048575 non-null object\n",
      "Tag           1048575 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ner_dataset.csv.gz', compression='gzip', encoding='ISO-8859-1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1048565</th>\n",
       "      <th>1048566</th>\n",
       "      <th>1048567</th>\n",
       "      <th>1048568</th>\n",
       "      <th>1048569</th>\n",
       "      <th>1048570</th>\n",
       "      <th>1048571</th>\n",
       "      <th>1048572</th>\n",
       "      <th>1048573</th>\n",
       "      <th>1048574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>47958</td>\n",
       "      <td>47958</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>through</td>\n",
       "      <td>London</td>\n",
       "      <td>to</td>\n",
       "      <td>protest</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>impact</td>\n",
       "      <td>.</td>\n",
       "      <td>Indian</td>\n",
       "      <td>forces</td>\n",
       "      <td>said</td>\n",
       "      <td>they</td>\n",
       "      <td>responded</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>TO</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1048575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1              2       3        4        5        \\\n",
       "sentence_id          1       1              1       1        1        1   \n",
       "words        Thousands      of  demonstrators    have  marched  through   \n",
       "pos                NNS      IN            NNS     VBP      VBN       IN   \n",
       "labels               O       O              O       O        O        O   \n",
       "\n",
       "            6       7        8       9        ... 1048565 1048566 1048567  \\\n",
       "sentence_id       1       1        1       1  ...   47958   47958   47959   \n",
       "words        London      to  protest     the  ...  impact       .  Indian   \n",
       "pos             NNP      TO       VB      DT  ...      NN       .      JJ   \n",
       "labels        B-geo       O        O       O  ...       O       O   B-gpe   \n",
       "\n",
       "            1048568 1048569 1048570    1048571 1048572 1048573 1048574  \n",
       "sentence_id   47959   47959   47959      47959   47959   47959   47959  \n",
       "words        forces    said    they  responded      to     the  attack  \n",
       "pos             NNS     VBD     PRP        VBD      TO      DT      NN  \n",
       "labels            O       O       O          O       O       O       O  \n",
       "\n",
       "[4 rows x 1048575 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4CdO30h_h67"
   },
   "source": [
    "## Basic Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "nHtZvIgdTiB9",
    "outputId": "8148d99a-145c-4d6a-87c3-bd9fc3bc6107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 4 columns):\n",
      "Sentence #    1048575 non-null object\n",
      "Word          1048575 non-null object\n",
      "POS           1048575 non-null object\n",
      "Tag           1048575 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(method='ffill')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y8wFwSqC-xu1"
   },
   "outputs": [],
   "source": [
    "df['sentence_id'] = [item.split(':')[1].strip() for item in df['Sentence #'].values]\n",
    "df['words'] = df['Word']\n",
    "df['pos'] = df['POS']\n",
    "df['labels'] = df['Tag']\n",
    "df = df[['sentence_id', 'words', 'pos', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239
    },
    "colab_type": "code",
    "id": "or8Tfxl-TiCB",
    "outputId": "1500ffdd-1322-4104-d2dd-6e20837eeea2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1048565</th>\n",
       "      <th>1048566</th>\n",
       "      <th>1048567</th>\n",
       "      <th>1048568</th>\n",
       "      <th>1048569</th>\n",
       "      <th>1048570</th>\n",
       "      <th>1048571</th>\n",
       "      <th>1048572</th>\n",
       "      <th>1048573</th>\n",
       "      <th>1048574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentence_id</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>47958</td>\n",
       "      <td>47958</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "      <td>47959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>through</td>\n",
       "      <td>London</td>\n",
       "      <td>to</td>\n",
       "      <td>protest</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>impact</td>\n",
       "      <td>.</td>\n",
       "      <td>Indian</td>\n",
       "      <td>forces</td>\n",
       "      <td>said</td>\n",
       "      <td>they</td>\n",
       "      <td>responded</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>TO</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1048575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1              2       3        4        5        \\\n",
       "sentence_id          1       1              1       1        1        1   \n",
       "words        Thousands      of  demonstrators    have  marched  through   \n",
       "pos                NNS      IN            NNS     VBP      VBN       IN   \n",
       "labels               O       O              O       O        O        O   \n",
       "\n",
       "            6       7        8       9        ... 1048565 1048566 1048567  \\\n",
       "sentence_id       1       1        1       1  ...   47958   47958   47959   \n",
       "words        London      to  protest     the  ...  impact       .  Indian   \n",
       "pos             NNP      TO       VB      DT  ...      NN       .      JJ   \n",
       "labels        B-geo       O        O       O  ...       O       O   B-gpe   \n",
       "\n",
       "            1048568 1048569 1048570    1048571 1048572 1048573 1048574  \n",
       "sentence_id   47959   47959   47959      47959   47959   47959   47959  \n",
       "words        forces    said    they  responded      to     the  attack  \n",
       "pos             NNS     VBD     PRP        VBD      TO      DT      NN  \n",
       "labels            O       O       O          O       O       O       O  \n",
       "\n",
       "[4 rows x 1048575 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hh8lDQ1VTiCH",
    "outputId": "77336516-099d-465b-c5a3-e7176d4118b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 35178, 42, 17)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentence_id.nunique(), df.words.nunique(), df.pos.nunique(), df.labels.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ql3nrlEYTiCJ"
   },
   "source": [
    "We have 47959 sentences that contain 35178 unique words.\n",
    "\n",
    "These sentences have a total of 42 unique POS tags and 17 unique NER tags in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zs5MJn1uTiCK"
   },
   "source": [
    "\n",
    "# Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "EYkVvfvJTiCL",
    "outputId": "f2c3d335-0465-4edc-a89a-740be63b60cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XOSvGvXQTiCO"
   },
   "source": [
    "# CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BfREwMsGTiCO"
   },
   "source": [
    "## Prepare Data\n",
    "\n",
    "CRF trains upon sequence of input data to learn transitions from one state (label) to another. \n",
    "\n",
    "To enable such an algorithm, __we need to define features__ which take into account different transitions. \n",
    "\n",
    "In the function ```word2features()``` below, we transform each word into a feature dictionary depicting the following attributes or features:\n",
    "\n",
    "+ __lower case of word__\n",
    "+ __suffix containing last 3 characters__\n",
    "+ __suffix containing last 2 characters__\n",
    "+ __flags to determine upper-case, title-case, numeric data and POS tag__\n",
    "\n",
    "We also attach __attributes related to previous and next words or tags to determine beginning of sentence (BOS) or end of sentence (EOS)__\n",
    "\n",
    "https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#let-s-use-conll-2002-data-to-build-a-ner-system\n",
    "\n",
    "In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wu-S2mmZAwjV"
   },
   "source": [
    "### Feature Engineering Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0a8sFLVuTiCR"
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EEz01_S8TiCV"
   },
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['words'].values.tolist(), \n",
    "                                                   s['pos'].values.tolist(), \n",
    "                                                   s['labels'].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ui1owUAVTiCa"
   },
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('sentence_id').apply(agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "bCZC4fFbTiCd",
    "outputId": "10225056-0b88-4cfa-e2f7-d25e3796d547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')])]\n"
     ]
    }
   ],
   "source": [
    "print(grouped_df[grouped_df.index == '1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "F0wUFmfmTiCg",
    "outputId": "993ba4f8-8a4b-43cf-9f9a-f58ca2ea1c27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "dDlJKsDUTiCm",
    "outputId": "f702993e-91fe-4b08-a536-c313a1b24361"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [s for s in grouped_df]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "Bgo0w5ThTiCq",
    "outputId": "53a5e2fa-7444-4f0e-8d13-6b52fe34cac2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'+1:postag': 'NNP',\n",
       "  '+1:postag[:2]': 'NN',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:word.lower()': 'london',\n",
       "  'BOS': True,\n",
       "  'bias': 1.0,\n",
       "  'postag': 'IN',\n",
       "  'postag[:2]': 'IN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'through',\n",
       "  'word[-2:]': 'gh',\n",
       "  'word[-3:]': 'ugh'},\n",
       " {'-1:postag': 'IN',\n",
       "  '-1:postag[:2]': 'IN',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:word.lower()': 'through',\n",
       "  'EOS': True,\n",
       "  'bias': 1.0,\n",
       "  'postag': 'NNP',\n",
       "  'postag[:2]': 'NN',\n",
       "  'word.isdigit()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isupper()': False,\n",
       "  'word.lower()': 'london',\n",
       "  'word[-2:]': 'on',\n",
       "  'word[-3:]': 'don'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(sentences[0][5:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r3Cy6Fd3TiCt",
    "outputId": "d16ab906-dc4f-4136-c536-512b042be3de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-geo']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2labels(sentences[0][5:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adx04n43TiCv"
   },
   "source": [
    "## Prepare Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jpp1oPhGTiCv",
    "outputId": "dfe1c1c3-0676-463d-b074-d7bd4e0cbe12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35969,), (11990,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([sent2features(s) for s in sentences])\n",
    "y = np.array([sent2labels(s) for s in sentences])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t3pfNvDOCfOk"
   },
   "source": [
    "## Sample Featureset & Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "colab_type": "code",
    "id": "-J33AHO5BzVs",
    "outputId": "32cf1d2a-724a-49dc-bb2d-4044bdb0c373"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+1:postag</th>\n",
       "      <th>+1:postag[:2]</th>\n",
       "      <th>+1:word.istitle()</th>\n",
       "      <th>+1:word.isupper()</th>\n",
       "      <th>+1:word.lower()</th>\n",
       "      <th>-1:postag</th>\n",
       "      <th>-1:postag[:2]</th>\n",
       "      <th>-1:word.istitle()</th>\n",
       "      <th>-1:word.isupper()</th>\n",
       "      <th>-1:word.lower()</th>\n",
       "      <th>...</th>\n",
       "      <th>bias</th>\n",
       "      <th>postag</th>\n",
       "      <th>postag[:2]</th>\n",
       "      <th>word.isdigit()</th>\n",
       "      <th>word.istitle()</th>\n",
       "      <th>word.isupper()</th>\n",
       "      <th>word.lower()</th>\n",
       "      <th>word[-2:]</th>\n",
       "      <th>word[-3:]</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>the</td>\n",
       "      <td>he</td>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>alleged</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>er</td>\n",
       "      <td>per</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>that</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>alleged</td>\n",
       "      <td>ed</td>\n",
       "      <td>ged</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>jimenez</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>alleged</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>that</td>\n",
       "      <td>at</td>\n",
       "      <td>hat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tipped</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>that</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>jimenez</td>\n",
       "      <td>ez</td>\n",
       "      <td>nez</td>\n",
       "      <td>B-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RP</td>\n",
       "      <td>RP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>off</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>jimenez</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tipped</td>\n",
       "      <td>ed</td>\n",
       "      <td>ped</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>jailed</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tipped</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RP</td>\n",
       "      <td>RP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>off</td>\n",
       "      <td>ff</td>\n",
       "      <td>off</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>drug</td>\n",
       "      <td>RP</td>\n",
       "      <td>RP</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>off</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>jailed</td>\n",
       "      <td>ed</td>\n",
       "      <td>led</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>trafficker</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>jailed</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>drug</td>\n",
       "      <td>ug</td>\n",
       "      <td>rug</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>fernando</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>drug</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>trafficker</td>\n",
       "      <td>er</td>\n",
       "      <td>ker</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>zevallos</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>trafficker</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>fernando</td>\n",
       "      <td>do</td>\n",
       "      <td>ndo</td>\n",
       "      <td>B-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>that</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>fernando</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>zevallos</td>\n",
       "      <td>os</td>\n",
       "      <td>los</td>\n",
       "      <td>I-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRP</td>\n",
       "      <td>PR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>he</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>zevallos</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>that</td>\n",
       "      <td>at</td>\n",
       "      <td>hat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>was</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>that</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>under</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PR</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>he</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>was</td>\n",
       "      <td>as</td>\n",
       "      <td>was</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>investigation</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>was</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>under</td>\n",
       "      <td>er</td>\n",
       "      <td>der</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>by</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>under</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>investigation</td>\n",
       "      <td>on</td>\n",
       "      <td>ion</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>two</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>investigation</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>agents</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>by</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>two</td>\n",
       "      <td>wo</td>\n",
       "      <td>two</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>working</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>two</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>agents</td>\n",
       "      <td>ts</td>\n",
       "      <td>nts</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>with</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>agents</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>working</td>\n",
       "      <td>ng</td>\n",
       "      <td>ing</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>u.s.</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>working</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>with</td>\n",
       "      <td>th</td>\n",
       "      <td>ith</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>drug</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>with</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>u.s.</td>\n",
       "      <td>S.</td>\n",
       "      <td>.S.</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>officials</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>u.s.</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>drug</td>\n",
       "      <td>ug</td>\n",
       "      <td>rug</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>drug</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>officials</td>\n",
       "      <td>ls</td>\n",
       "      <td>als</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>officials</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   +1:postag +1:postag[:2] +1:word.istitle() +1:word.isupper()  \\\n",
       "0         NN            NN             False             False   \n",
       "1        VBD            VB             False             False   \n",
       "2         IN            IN             False             False   \n",
       "3        NNP            NN              True             False   \n",
       "4        VBD            VB             False             False   \n",
       "5         RP            RP             False             False   \n",
       "6         JJ            JJ             False             False   \n",
       "7         NN            NN             False             False   \n",
       "8         NN            NN             False             False   \n",
       "9        NNP            NN              True             False   \n",
       "10       NNP            NN              True             False   \n",
       "11        IN            IN             False             False   \n",
       "12       PRP            PR             False             False   \n",
       "13       VBD            VB             False             False   \n",
       "14        IN            IN             False             False   \n",
       "15        NN            NN             False             False   \n",
       "16        IN            IN             False             False   \n",
       "17        CD            CD             False             False   \n",
       "18       NNS            NN             False             False   \n",
       "19       VBG            VB             False             False   \n",
       "20        IN            IN             False             False   \n",
       "21       NNP            NN              True              True   \n",
       "22        NN            NN             False             False   \n",
       "23       NNS            NN             False             False   \n",
       "24         .             .             False             False   \n",
       "25       NaN           NaN               NaN               NaN   \n",
       "\n",
       "   +1:word.lower() -1:postag -1:postag[:2] -1:word.istitle()  \\\n",
       "0        newspaper       NaN           NaN               NaN   \n",
       "1          alleged        DT            DT              True   \n",
       "2             that        NN            NN             False   \n",
       "3          jimenez       VBD            VB             False   \n",
       "4           tipped        IN            IN             False   \n",
       "5              off       NNP            NN              True   \n",
       "6           jailed       VBD            VB             False   \n",
       "7             drug        RP            RP             False   \n",
       "8       trafficker        JJ            JJ             False   \n",
       "9         fernando        NN            NN             False   \n",
       "10        zevallos        NN            NN             False   \n",
       "11            that       NNP            NN              True   \n",
       "12              he       NNP            NN              True   \n",
       "13             was        IN            IN             False   \n",
       "14           under       PRP            PR             False   \n",
       "15   investigation       VBD            VB             False   \n",
       "16              by        IN            IN             False   \n",
       "17             two        NN            NN             False   \n",
       "18          agents        IN            IN             False   \n",
       "19         working        CD            CD             False   \n",
       "20            with       NNS            NN             False   \n",
       "21            u.s.       VBG            VB             False   \n",
       "22            drug        IN            IN             False   \n",
       "23       officials       NNP            NN              True   \n",
       "24               .        NN            NN             False   \n",
       "25             NaN       NNS            NN             False   \n",
       "\n",
       "   -1:word.isupper() -1:word.lower()  ... bias postag  postag[:2]  \\\n",
       "0                NaN             NaN  ...  1.0     DT          DT   \n",
       "1              False             the  ...  1.0     NN          NN   \n",
       "2              False       newspaper  ...  1.0    VBD          VB   \n",
       "3              False         alleged  ...  1.0     IN          IN   \n",
       "4              False            that  ...  1.0    NNP          NN   \n",
       "5              False         jimenez  ...  1.0    VBD          VB   \n",
       "6              False          tipped  ...  1.0     RP          RP   \n",
       "7              False             off  ...  1.0     JJ          JJ   \n",
       "8              False          jailed  ...  1.0     NN          NN   \n",
       "9              False            drug  ...  1.0     NN          NN   \n",
       "10             False      trafficker  ...  1.0    NNP          NN   \n",
       "11             False        fernando  ...  1.0    NNP          NN   \n",
       "12             False        zevallos  ...  1.0     IN          IN   \n",
       "13             False            that  ...  1.0    PRP          PR   \n",
       "14             False              he  ...  1.0    VBD          VB   \n",
       "15             False             was  ...  1.0     IN          IN   \n",
       "16             False           under  ...  1.0     NN          NN   \n",
       "17             False   investigation  ...  1.0     IN          IN   \n",
       "18             False              by  ...  1.0     CD          CD   \n",
       "19             False             two  ...  1.0    NNS          NN   \n",
       "20             False          agents  ...  1.0    VBG          VB   \n",
       "21             False         working  ...  1.0     IN          IN   \n",
       "22             False            with  ...  1.0    NNP          NN   \n",
       "23              True            u.s.  ...  1.0     NN          NN   \n",
       "24             False            drug  ...  1.0    NNS          NN   \n",
       "25             False       officials  ...  1.0      .           .   \n",
       "\n",
       "   word.isdigit() word.istitle()  word.isupper()   word.lower()  word[-2:]  \\\n",
       "0           False           True           False            the         he   \n",
       "1           False          False           False      newspaper         er   \n",
       "2           False          False           False        alleged         ed   \n",
       "3           False          False           False           that         at   \n",
       "4           False           True           False        jimenez         ez   \n",
       "5           False          False           False         tipped         ed   \n",
       "6           False          False           False            off         ff   \n",
       "7           False          False           False         jailed         ed   \n",
       "8           False          False           False           drug         ug   \n",
       "9           False          False           False     trafficker         er   \n",
       "10          False           True           False       fernando         do   \n",
       "11          False           True           False       zevallos         os   \n",
       "12          False          False           False           that         at   \n",
       "13          False          False           False             he         he   \n",
       "14          False          False           False            was         as   \n",
       "15          False          False           False          under         er   \n",
       "16          False          False           False  investigation         on   \n",
       "17          False          False           False             by         by   \n",
       "18          False          False           False            two         wo   \n",
       "19          False          False           False         agents         ts   \n",
       "20          False          False           False        working         ng   \n",
       "21          False          False           False           with         th   \n",
       "22          False           True            True           u.s.         S.   \n",
       "23          False          False           False           drug         ug   \n",
       "24          False          False           False      officials         ls   \n",
       "25          False          False           False              .          .   \n",
       "\n",
       "   word[-3:]  label  \n",
       "0        The      O  \n",
       "1        per      O  \n",
       "2        ged      O  \n",
       "3        hat      O  \n",
       "4        nez  B-per  \n",
       "5        ped      O  \n",
       "6        off      O  \n",
       "7        led      O  \n",
       "8        rug      O  \n",
       "9        ker      O  \n",
       "10       ndo  B-per  \n",
       "11       los  I-per  \n",
       "12       hat      O  \n",
       "13        he      O  \n",
       "14       was      O  \n",
       "15       der      O  \n",
       "16       ion      O  \n",
       "17        by      O  \n",
       "18       two      O  \n",
       "19       nts      O  \n",
       "20       ing      O  \n",
       "21       ith      O  \n",
       "22       .S.  B-geo  \n",
       "23       rug      O  \n",
       "24       als      O  \n",
       "25         .      O  \n",
       "\n",
       "[26 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(X_train[1]), pd.DataFrame({'label': y_train[1]})], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B56GXmxsTiC1"
   },
   "source": [
    "# Building Models with sklearn-crfsuite\n",
    "\n",
    "__`sklearn-crfsuite`__ is a thin [CRFsuite (python-crfsuite)](https://github.com/scrapinghub/python-crfsuite) wrapper which provides scikit-learn-compatible sklearn_crfsuite.CRF estimator: you can use e.g. scikit-learn model selection utilities (cross-validation, hyperparameter optimization) with it, or save/load CRF models using joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "qlgimPwTTiC4",
    "outputId": "705fc5e4-8490-4c99-d98a-55e2cde6db75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-crfsuite\n",
      "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: six in c:\\users\\shree.charran\\.conda\\envs\\py35\\lib\\site-packages (from sklearn-crfsuite) (1.15.0)\n",
      "Collecting python-crfsuite>=0.8.3\n",
      "  Downloading python_crfsuite-0.9.7-cp35-cp35m-win_amd64.whl (153 kB)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\shree.charran\\.conda\\envs\\py35\\lib\\site-packages (from sklearn-crfsuite) (4.50.2)\n",
      "Installing collected packages: tabulate, python-crfsuite, sklearn-crfsuite\n",
      "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6 tabulate-0.8.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xuxvcfIoTiC_"
   },
   "source": [
    "## Your Turn: Train the model!\n",
    "\n",
    "Train the model using the default configurations mentioned in the [sklearn-crfsuite API docs](https://sklearn-crfsuite.readthedocs.io/en/latest/api.html)\n",
    "\n",
    "We have filled in some of these for your convenience as follows.\n",
    "\n",
    "- __algorithm:__ the training algorithm. We use [L-BFGS](https://en.wikipedia.org/wiki/Limited-memory_BFGS) for gradient descent for optimization and getting model parameters\n",
    "- __c1:__ Coefficient for Lasso (L1) regularization\n",
    "- __c2:__ Coefficient for Ridge (L2) regularization\n",
    "- __all_possible_transitions:__ Specify whether CRFsuite generates transition features that do not even occur in the training data\n",
    "\n",
    "\n",
    "__Note:__ If the model is taking too long to train, you can load up the pre-trained model using the code after the training cells and use that for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUMlk4QFTiDA"
   },
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs',\n",
    "                           c1=0.1,\n",
    "                           c2=0.1,\n",
    "                           max_iterations=100,\n",
    "                           all_possible_transitions=True,\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "90-1GIFzTiDW"
   },
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(crf, 'ner_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "u2aYAFE0TiDf",
    "outputId": "670eea52-b8d7-45b3-d516-5b99c40172bf"
   },
   "outputs": [],
   "source": [
    "crf = joblib.load('ner_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 968
    },
    "colab_type": "code",
    "id": "IaFRjCqcER2g",
    "outputId": "962c7b33-bdaa-411f-be70-9e9c340ddacc"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OQqRw060TiDj",
    "outputId": "be77eeaa-547f-497e-c209-d5e77da46b05"
   },
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iI25InSYTiDn",
    "outputId": "fa09a9a7-8a77-4881-f72b-ca92035e103f"
   },
   "outputs": [],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7lIbMwpTiDs"
   },
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import metrics as crf_metrics\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "QazYuXTfTiDw",
    "outputId": "10f2222c-6d24-4df7-d6ce-bb535c9223f7"
   },
   "outputs": [],
   "source": [
    "print(crf_metrics.flat_classification_report(y_test, y_pred, labels=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Qj9a3C2TiD0"
   },
   "source": [
    "### Prepare Sample Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "RBqzi5lOTiD1",
    "outputId": "631d5739-2347-4efe-bc62-6d868be4a13a"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"Three more countries have joined an “international grand committee” of parliaments, adding to calls for \n",
    "Facebook’s boss, Mark Zuckerberg, to give evidence on misinformation to the coalition. Brazil, Latvia and Singapore \n",
    "bring the total to eight different parliaments across the world, with plans to send representatives to London on 27 \n",
    "November with the intention of hearing from Zuckerberg. Since the Cambridge Analytica scandal broke, the Facebook chief \n",
    "has only appeared in front of two legislatures: the American Senate and House of Representatives, and the European parliament. \n",
    "Facebook has consistently rebuffed attempts from others, including the UK and Canadian parliaments, to hear from Zuckerberg. \n",
    "He added that an article in the New York Times on Thursday, in which the paper alleged a pattern of behaviour from Facebook \n",
    "to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly \n",
    "dealt with within Facebook.”\n",
    "\"\"\"\n",
    "\n",
    "text = re.sub(r'\\n', '', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LpGBCYozTiD6"
   },
   "source": [
    "### NER Tagging with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "colab_type": "code",
    "id": "Y1IEl-zdTiD9",
    "outputId": "74cd153f-40f0-44c1-8bdb-44892f6e6793"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " more countries have joined an “international grand committee” of parliaments, adding to calls for Facebook’s boss, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mark Zuckerberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", to give evidence on misinformation to the coalition. \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Latvia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Singapore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " bring the total to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    eight\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " different parliaments across the world, with plans to send representatives to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    London\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    27 November\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " with the intention of hearing from \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zuckerberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". Since the Cambridge Analytica scandal broke, the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " chief has only appeared in front of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " legislatures: \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the American Senate\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    House of Representatives\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    European\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " parliament. Facebook has consistently rebuffed attempts from others, including the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Canadian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " parliaments, to hear from \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zuckerberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". He added that an article in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the New York Times\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thursday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", in which the paper alleged a pattern of behaviour from \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly dealt with within \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".”</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "text_nlp = nlp(text)\n",
    "displacy.render(text_nlp, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nEBPbT3wTiEB"
   },
   "source": [
    "### Pipeline Step 1\n",
    "\n",
    "- Tokenize Text\n",
    "- POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ilhggzoTTiEC",
    "outputId": "19a57be9-d439-4960-a495-2c5fabef1abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ZoAK2090ErMd",
    "outputId": "9da2f22b-b6c5-4af4-8a21-d63bb6c1d13c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Three', 'CD'),\n",
       " ('more', 'JJR'),\n",
       " ('countries', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('joined', 'VBN'),\n",
       " ('an', 'DT'),\n",
       " ('“', 'NNP'),\n",
       " ('international', 'JJ'),\n",
       " ('grand', 'JJ'),\n",
       " ('committee', 'NN')]"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tokens = nltk.word_tokenize(text)\n",
    "text_pos = nltk.pos_tag(text_tokens)\n",
    "text_pos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFiJDfXNTiEE"
   },
   "source": [
    "### Pipeline Step 2\n",
    "- Extract Features from the POS tagged text document\n",
    "- Hint: Use `sent2features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "jIyOgUsUTiEF",
    "outputId": "149c7d29-c221-4ae1-998a-c05d8f7c3d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'+1:postag': 'JJR',\n",
       " '+1:postag[:2]': 'JJ',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:word.lower()': 'more',\n",
       " 'BOS': True,\n",
       " 'bias': 1.0,\n",
       " 'postag': 'CD',\n",
       " 'postag[:2]': 'CD',\n",
       " 'word.isdigit()': False,\n",
       " 'word.istitle()': True,\n",
       " 'word.isupper()': False,\n",
       " 'word.lower()': 'three',\n",
       " 'word[-2:]': 'ee',\n",
       " 'word[-3:]': 'ree'}"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [sent2features(text_pos)]\n",
    "features[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKnFDgITTiEK"
   },
   "source": [
    "### Pipeline Step 3\n",
    "- Use the CRF Model `crf` to predict on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mbQVjCh2TiEL",
    "outputId": "c69ccf01-c0a2-4d26-ec8a-bd327fbf8384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-art', 'I-art']"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = crf.predict(features)\n",
    "doc_labels = labels[0]\n",
    "doc_labels[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-386sJeSTiEO"
   },
   "source": [
    "### Pipeline Step 4\n",
    "- Combine text tokens with NER Tags\n",
    "- Retrieve relevant named entities from NER Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "5b2JHzNiTiEP",
    "outputId": "3aa01dd8-437a-42ee-f8d4-03c63ce0b278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Three', 'O'), ('more', 'O'), ('countries', 'O'), ('have', 'O'), ('joined', 'O'), ('an', 'O'), ('“', 'O'), ('international', 'O'), ('grand', 'O'), ('committee', 'O'), ('”', 'O'), ('of', 'O'), ('parliaments', 'O'), (',', 'O'), ('adding', 'O'), ('to', 'O'), ('calls', 'O'), ('for', 'O'), ('Facebook', 'B-art'), ('’', 'I-art'), ('s', 'O'), ('boss', 'O'), (',', 'O'), ('Mark', 'B-per'), ('Zuckerberg', 'I-per'), (',', 'O'), ('to', 'O'), ('give', 'O'), ('evidence', 'O'), ('on', 'O'), ('misinformation', 'O'), ('to', 'O'), ('the', 'O'), ('coalition', 'O'), ('.', 'O'), ('Brazil', 'B-geo'), (',', 'O'), ('Latvia', 'B-org'), ('and', 'I-org'), ('Singapore', 'I-org'), ('bring', 'O'), ('the', 'O'), ('total', 'O'), ('to', 'O'), ('eight', 'O'), ('different', 'O'), ('parliaments', 'O'), ('across', 'O'), ('the', 'O'), ('world', 'O'), (',', 'O'), ('with', 'O'), ('plans', 'O'), ('to', 'O'), ('send', 'O'), ('representatives', 'O'), ('to', 'O'), ('London', 'B-geo'), ('on', 'O'), ('27', 'B-tim'), ('November', 'I-tim'), ('with', 'O'), ('the', 'O'), ('intention', 'O'), ('of', 'O'), ('hearing', 'O'), ('from', 'O'), ('Zuckerberg', 'B-geo'), ('.', 'O'), ('Since', 'O'), ('the', 'O'), ('Cambridge', 'B-org'), ('Analytica', 'I-org'), ('scandal', 'O'), ('broke', 'O'), (',', 'O'), ('the', 'O'), ('Facebook', 'B-org'), ('chief', 'O'), ('has', 'O'), ('only', 'O'), ('appeared', 'O'), ('in', 'O'), ('front', 'O'), ('of', 'O'), ('two', 'O'), ('legislatures', 'O'), (':', 'O'), ('the', 'O'), ('American', 'B-gpe'), ('Senate', 'B-org'), ('and', 'I-org'), ('House', 'I-org'), ('of', 'I-org'), ('Representatives', 'I-org'), (',', 'O'), ('and', 'O'), ('the', 'O'), ('European', 'B-org'), ('parliament', 'I-org'), ('.', 'O'), ('Facebook', 'B-org'), ('has', 'O'), ('consistently', 'O'), ('rebuffed', 'O'), ('attempts', 'O'), ('from', 'O'), ('others', 'O'), (',', 'O'), ('including', 'O'), ('the', 'O'), ('UK', 'B-org'), ('and', 'O'), ('Canadian', 'B-gpe'), ('parliaments', 'O'), (',', 'O'), ('to', 'O'), ('hear', 'O'), ('from', 'O'), ('Zuckerberg', 'B-geo'), ('.', 'O'), ('He', 'O'), ('added', 'O'), ('that', 'O'), ('an', 'O'), ('article', 'O'), ('in', 'O'), ('the', 'O'), ('New', 'B-org'), ('York', 'I-org'), ('Times', 'I-org'), ('on', 'O'), ('Thursday', 'B-tim'), (',', 'O'), ('in', 'O'), ('which', 'O'), ('the', 'O'), ('paper', 'O'), ('alleged', 'O'), ('a', 'O'), ('pattern', 'O'), ('of', 'O'), ('behaviour', 'O'), ('from', 'O'), ('Facebook', 'B-org'), ('to', 'O'), ('“', 'O'), ('delay', 'O'), (',', 'O'), ('deny', 'O'), ('and', 'O'), ('deflect', 'O'), ('”', 'O'), ('negative', 'O'), ('news', 'O'), ('stories', 'O'), (',', 'O'), ('“', 'O'), ('raises', 'O'), ('further', 'O'), ('questions', 'O'), ('about', 'O'), ('how', 'O'), ('recent', 'O'), ('data', 'O'), ('breaches', 'O'), ('were', 'O'), ('allegedly', 'O'), ('dealt', 'O'), ('with', 'O'), ('within', 'O'), ('Facebook', 'B-art'), ('.', 'O'), ('”', 'O')]\n"
     ]
    }
   ],
   "source": [
    "text_ner = [(token, tag) for token, tag in zip(text_tokens, doc_labels)]\n",
    "print(text_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3I_W7YXTiER"
   },
   "outputs": [],
   "source": [
    "named_entities = []\n",
    "temp_entity_name = ''\n",
    "temp_named_entity = None\n",
    "for term, tag in text_ner:\n",
    "    if tag != 'O':\n",
    "        temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "        temp_named_entity = (temp_entity_name, tag)\n",
    "    else:\n",
    "        if temp_named_entity:\n",
    "            named_entities.append(temp_named_entity)\n",
    "            temp_entity_name = ''\n",
    "            temp_named_entity = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "Y5r-7JspTiEU",
    "outputId": "181ce7da-0578-4c90-f190-1ca5380268c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook ’</td>\n",
       "      <td>I-art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>I-per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brazil</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Latvia and Singapore</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27 November</td>\n",
       "      <td>I-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zuckerberg</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cambridge Analytica</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>American Senate and House of Representatives</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>European parliament</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UK</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Canadian</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zuckerberg</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>New York Times</td>\n",
       "      <td>I-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>B-tim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>B-art</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Entity    Tag\n",
       "0                                     Facebook ’  I-art\n",
       "1                                Mark Zuckerberg  I-per\n",
       "2                                         Brazil  B-geo\n",
       "3                           Latvia and Singapore  I-org\n",
       "4                                         London  B-geo\n",
       "5                                    27 November  I-tim\n",
       "6                                     Zuckerberg  B-geo\n",
       "7                            Cambridge Analytica  I-org\n",
       "8                                       Facebook  B-org\n",
       "9   American Senate and House of Representatives  I-org\n",
       "10                           European parliament  I-org\n",
       "11                                      Facebook  B-org\n",
       "12                                            UK  B-org\n",
       "13                                      Canadian  B-gpe\n",
       "14                                    Zuckerberg  B-geo\n",
       "15                                New York Times  I-org\n",
       "16                                      Thursday  B-tim\n",
       "17                                      Facebook  B-org\n",
       "18                                      Facebook  B-art"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(named_entities, columns=['Entity', 'Tag'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "03_Building_NER_Models_CRF.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
